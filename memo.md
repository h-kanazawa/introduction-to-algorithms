[アルゴリズムイントロダクション 第3版 総合版](http://amzn.asia/d/eELpRf1)（日本語・Kindle版）

# 2

## 正当性の証明

多くのアルゴリズムはループを利用する。こうしたアルゴリズムの正当性の証明するは初期条件、ループ内条件、終了条件の3つを示す必要がある。数学的帰納法と似ている。
資源（時間や記憶量）を解析するのにランダムアクアスマシンを利用する

## 実行時間の解析

- 最悪実行時間か平均実行時間か
- 増加のオーダーが大事
  - が、定数因子も無いわけではないので、問題サイズが小さい場合、敢えてオーダーの大きいアルゴリズムを利用するほうが速いことがある
  - 漸近的な asymptotic 効率とも言う

## 基本的アプローチ

- 逐次添加法 incremental approach
- 分割統治法 devide and conquer
  - 問題を分割し、サイズの小さな部分問題を解いた後に、それらの解を組み合わせて解を導く方法
  - 分割、統治、結合

## 挿入ソート insertion sort

- 逐次添加法
- O(n^2)

## マージソート merge sort

- 分割統治法
- 番兵 sentinel を使うことで、プログラムがある位置まで達成したことを判定するテクニックがある。
- O(n * lg(n))
- in placeではない

# 3

## 漸近記法

アルゴリズムの実行時間を記述するために用いる

- Θ記法
  - ある正の定数n0が存在し、すべてのn>=n0に対して...関数の値域が上からも下からも制限できる関数の集合
- O記法 ビッグオー
  - 漸近的上界
  - ある正の定数n0が存在し、すべてのn>=n0に対して...関数の地域が上から制限できる関数の集合
- Ω記法 ビッグオメガ
  - 漸近的下界
  - ある正の定数n0が存在し、すべてのn>=n0に対して...関数の地域が下から制限できる関数の集合
- o記法 リトルオー
  - タイトであるとは言えない上界
- ω記法 リトルオメガ
  - タイトであるとは言えない下界

学術的にはこのような定義だが、上界・下界両方に対してO記法でまとめられてしまうことも

# 4 分割統治

- 分割: 問題をいくつかの部分問題に分割する。部分問題は元の問題と同じ構造であり、元の問題より小さい。
- 統治: 部分問題を再帰的に解く。
- 結合: 部分問題の組み合わせて、元の問題の解を求める。

しばしば漸化式で実行時間T(n)を表現する。
漸化式を解くのに、置換え法、再帰木法、マスター法が存在する。

- 組換え法 substitution method
  - 解の形を推定し、数学的帰納法で推定が正しいことを証明する。天下り的。
- 再帰木法 recursion tree method
  - 木の深さごとにコストを求めて、そのコストを総和することで求める。
- マスター法 master method
  - `T(n) = aT(n/b) + f(n)` (a>=1, b>=1, f(n)は漸近的に正)を解く方法

## 最大部分配列問題 maximum subarray problem

総当たり戦略で解くとΩ(n^2)であるが、分割統治法でΘ(n*lg(n))で解ける

## 行列積

n x n行列A, Bの積を求める。
素直な分割統治で解くとΘ(n^3)である。
Strassenの方法ではΘ(n^lg(7))で解ける。

# 5 確率的解析と乱択アルゴリズム

乱択アルゴリズムを用いることで、アルゴリズムの期待実行時間を求める。

# II ソートと順序統計量

ソートアルゴリズムまとめ

|アルゴリズム|最悪実行時間|平均/期待実行時間|in place?|比較ソート?|
|:--|:--|:--|:--|:--|
|挿入ソート|Θ(n^2)|Θ(n^2)|Yes|Yes|
|マージソート|O(n * lg(n))|O(n * lg(n))|No|Yes|
|ヒープソート|O(n * lg(n))|-|Yes|Yes|
|クイックソート|Θ(n^2)|O(n * lg(n)) 期待時間|Yes|Yes|
|計数ソート|Θ(k + n)|Θ(k + n)|No|No|
|基数ソート|Θ(d(k + n))|Θ(d(k + n))|No|No|
|バケツソート|Θ(n^2)|Θ(n)|No|No|

# 6 ヒープソート heap sort

## ヒープ heap

ヒープはヒープ条件を満たすツリー型データ構造。

- min-heapのヒープ条件
  - 子要素のキー >= 親要素のキー
- max-heapのヒープ条件
  - 子要素のキー <= 親要素のキー

最下位レベルは左から順に埋まっている。
具体的な実装は配列で実現できる。

- 2分木の場合、ヒープの高さはΘ(lg(n))
- ヒープ条件を維持する手続き max-heapify に O(lg(n))
- 未ソートの配列からmax-heapを構築する手続き build-max-heap に O(n)
- ソートする手続き heapsort に O(n * lg(n))

## 優先度付きキュー priority queue

優先度（key）を持った集合Sを管理するための抽象データ構造で次の操作を持つもの

- insert: Sにkey付き要素を挿入する
- (option) maximum: 最大のkeyを持つSの要素を返す
- extract-max: 最大のkeyを持つSの要素を削除し、その要素を返す
- (option) increse-key: Sの要素のkeyをkに増加させる。

ハッシュテーブルを実装に使った場合、insertはO(1)だが、extract-maxはO(n)
ヒープを実装に使った場合、insertもextra-maxもO(lg(n))

# 7 クイックソート quick sort

最悪実行時間はΘ(n^2)だが、期待実行時間はΘ(n * lg(n))で、かつ隠れた定数部分が小さい。
in placeでできる。

分割統治法である。
- 分割: 分割点qを決め、qより左の配列はすべてq以下で、qより右の配列はすべてq以上となるように配列を並び替え、分割する。
- 統治: qの左右の配列をそれぞれ再帰的にソートする。
- 結合: 何もしなくて良い。ソート済みである。

分割点の決め方を乱択化することで確率的な解析が可能になる。

# 8 線形時間ソート

## 計数ソート counting sort

要素の範囲を限定した配列のソート
入力はn個の要素（0~kの範囲の整数）からなる配列

長さk+1の配列Cを一時領域として持ち、C[i]の値が `i` 以下の要素数となるようにカウントしていく。

このソートは安定性 stability がある。
安定性とは、同じ値の要素は入力の順序そのままの順序で出力されるというもの。

## 基数ソート radix sort

d桁のm進数の数字をソートする。
1番目の位（1の位）で安定ソート、2番目の位で安定ソート...d番目の位で安定ソート、とd回の安定ソートを行う。

パンチカードのためのソートで、現在では見かけることはない。

## バケツソート bucket sort

バケットソート、bin sortとも。
入力が一様分布 [0,1) から抽出されると仮定する。

n個のバケツ（例えばハッシュテーブル）を用意する。[0,1) をn個の区間に分割する。入力配列のある要素がi番目の区間に当てはまる場合はi番目のバケツに挿入する。バケツは挿入された順序を保持する。

# 9 中央値と順序統計量

配列の中のi番目順序統計量（例えば最小値、中央値、最大値など）を探すのにソートする必要はない。

最大値、最小値はn-1回の比較で十分なことはすぐに分かる。実は、最大値と最小値を同時に探すのは2n-2回ではなく3*(n/2)回の比較でよい。配列を2つずつピックアップし、それらを比較（1回目）し、小さい方を最小値と比較（2回目）、大きい方を最大値と比較（3回目）すればよいからだ。

一般化したi番目順序統計量の場合もクイックソートに似た分割と探索を繰り返すことで見つけることができる。教科書ではrandomized selectという関数名になっている。期待実行時間はΘ(n)。

実は最悪実行時間がO(n)であるアルゴリズムも存在する。quick selectとも呼ばれる。

- 入力配列を5個の要素からなるグループに分割する。nが5で割り切れないときは1~4個の配列がひとつできる。O(n)
- 各グループの要素をinsert sortでソートする。それぞれグループの中央値を選択する。O(n)
- こうして得られた約n/5個の中央値の中から再帰的に中央値を見つける。T(n/5)
- randomized selectの分割パートのアルゴリズムを改良し、中央値をピボットとして利用する。O(n)
- 再帰的にi番目に小さい要素を見つける。T(7 * n / 10 + 6)

再帰する際の問題インスタンスサイズの大きさが `7 * n / 10 + 6` になるのがポイント。

次のような漸化式を得る。

- T(n) <= T(n/5) + T(7n/10+6) + O(n)   (n >= 140)
- T(n) <= O(1)                         (n < 140)

証明は組み換え法でできる。

# 10 基本データ構造

## スタック stack

配列に加えtop位置を保持することで、pushもpopもO(1)で実現できる。

## キュー queue

長さnの配列とheadとtailを保持することでenqueueとdequeueをO(1)で実現できる。

## 連結リスト linked list

双方向の連結リストはheadとtail、各要素はnextとprevを持つ。
番兵 sentinel を用いると手続きをコードを単純化できる。

|op|unsorted, single|sorted, single|unsorted, double|sorted, double|
|:--|:--|:--|:--|:--|
|search|n|n|n|n|
|insert|1|n|1|n|
|delete|n|n|1|1|
|successor|n|1|n|1|
|predecessor|n|n|n|1|
|minimum|n|1|n|1|
|maximum|n|n|n|1|

## 2分木 binary tree

## 分岐数に制約のない根付き木

左-子・右-兄弟表現を用いると良い。あるノードは子供のうち最も左の子のポインタ格納スペースと、弟のポインタの格納スペースを保持する。

# 11 ハッシュ表

## ハッシュ表 hash table

キーのハッシュ値の枠に要素を保持する。ハッシュ関数を普遍集合Uから{0,1,...,m-1}への関数とする。衝突した場合はチェイン法 chaining によって、unserted double linked listに保存する。

- insert
  - 最悪実行時間 O(1)
- delete
  - 最悪実行時間 O(1)
- search
  - 最悪実行時間 O(n)
  - 平均実行時間 Θ(1 + n/m)

mがnに比例するなら平均実行時間はO(1)である。

ハッシュ関数を設計する。優れたハッシュ関数は出力がおよそ均等に分布する。

## 除算法 division method

キーが自然数なら枠数mで割った余り mod をキーにする方法が考えられる。
2のべき乗に近くない素数をmに選択するとよい。

## 乗算法 multiplication method

キーkに定数A(0<A<1)を掛け、このk*Aの小数部分にmを掛けた値の小数部分を切り捨てる
h(k) = {m * (k * A mod 1)}の整数部分
mの値に制限はないが、計算が速い2の冪乗を選択すると良い。
Aは(√5-1)/2に近いと良い（らしい）。
32bit整数の場合、2654435769/2^32が最も(√5-1)/2に近い。

## 万能ハッシュ法 universal hashing

キーの普遍集合Uを{0,1,...m-1}へ移すハッシュ関数の有限集合H
任意の異なるキーの組k,l ∈ Uに対して、h(k)=h(l)を満たすハッシュ関数h ∈ Hの個数がたかだか|H|/m
のときHは万能という。

万能ハッシュ法は万能ハッシュ関数の集合Hからランダムに選択する。

すべてのキーが0~p-1の範囲に入る大きな素数pを選択
a ∈ {0, 1, ..., p-1}
b ∈ {1, 2, ..., p-1}

h_ab(k) = ((a * k + b) mod p) mod m

このハッシュ関数全体からなる族は万能である。

## オープンアドレス指定法 open addressing

チェイン法と異なり、各キーに対する枠には1要素しか入らない。

長さmの配列を用意する。初期状態はすべてNilである。

- insert
  - キーを置ける空の枠を求めて探査 probe する。
  - ハッシュ関数は引数にキーを用いる。置換である。
  - h(入力キー, i)が埋まっていたら、
  - h(入力キー, i + 1)が空いているか確認する。
  - このようにキーを巡る順序を探査列と呼ぶ。
- search
  - insertと同じように探査列を辿っていき、キーを見るけるか、Nilが返ってくるまで探索する。
- delete
  - 削除した枠にNilではなく、deleteフラグを置く。

- 探査列の構築方法。どれも一様ハッシュではなく、近似。

- 線形探索法 linear probing
  - ハッシュ関数: `(h'(k) + i) mod m`
  - 実装は簡単だが、主クラスタ化という探査時間が悪化する問題を抱えている。
  - 探査列集合のサイズ: Θ(m)
- 2次関数探査法 quadratic probing
  - ハッシュ関数: `(h'(k) + c1 * i + c2 * i^2) mod m`
  - 線形探査法よりはるかに良いが、副クラスタ化と呼ばれる問題を抱えている。
  - ハッシュ表を完全に利用するためにはc1, c2, mを上手く選ぶ必要がある。
    - mが2のべき乗なら、c1=c2=1/2がよい。
  - 探査列集合のサイズ: Θ(m)
- ダブルハッシュ法
  - ハッシュ関数: `(h1'(k) + i * h2'(k)) mod m`
  - h1'(k)とh2'(k)はmの倍数ではないようにする。
  - 探査列集合のサイズ: Θ(m^2)

# 12 2分探索木

## 2分探索木 binary search tree

左の子のキー <= 自身のキー <= 右の子のキー の条件を満たす2分木

木の高さをhとする。削除と挿入を用いて構築された2分木の高さの平均については何も知られていない。

- 中間順序木巡回 inorder tree walk
  - Θ(n) キーがソートされた列にできる
- search
  - O(h) 最大h回の比較をして子ノードへ進む
- minimum (maximum)
  - O(h) 左（右）のノードをたどる
- successor (predecessor)
  - O(h) 右のノードがあれば、その中のminimumを、なければ1つ親のノードへ移り、...と進める
- insert
  - O(h) 挿入すべき位置へ最大h回の比較をして子ノードへ進む
- delete
  - O(h) 複雑。子・孫の有無によってパターン分けして考える

## 基数木 radix tree (trie)

長さmの文字列をキーにして考える。
文字列がビット列の場合は、深さiの接点で下からi桁目のビットが0なら左、1なら右となる2分木。
辞書順でソートできる。

# 13 2色木

## 2色木 red black tree

赤黒木とも。
接点が赤or黒の色を持つ2分探索木。rootからleafまでの長さが最短のものと最長のもので2倍以内に収まっている。平衡二分木のひとつ。以下の条件を満たす

- rootは黒
- leafはNilであり、黒
- 赤の子供は黒
- あるnodeからleafまでに含まれる黒nodeの数はすべて同じ

insert, delete時はrotate操作を行うことで、木が条件を満たせるように保つ。高さhが2 * lg(n + 1)以下なので、2分探索木の各種操作がO(lg(n))で実現できる。操作の実装は割と複雑。

## ALV木 AVL tree

平衡二分木のひとつ。leafまでの高さの違いが高々1という成約がある。2色木と同様に、insert, deleteで高さの差が2以上になったらbalanceという操作によって平衡を保つ。

# 14 データ構造の補強

新しいデータ構造の開発

- 基礎となるデータ構造の選択
- 追加情報を定める
- 基本操作が維持できるか確認する。計算量オーダーはどうなるかを検討する。
- 新しい操作を開発する。

## 順序統計量木 order-statistic tree

順序統計量操作（集合の中でi番目に小さい要素の選択など）を高速に行うために2色木を改良したもの。各nodeにsize属性を持つ。これは各nodeをrootとする部分技の内部node数を格納する。これによってi番目要素の選択がO(lg(n))で実行できる。

## 区間木 interval tree

各nodeが閉区間 [t1, t2] （ただしt1<=t2）を保持する2色木の改良版。あるnodeの下端点<=左の子の上端点、あるnodeの上端点<=右の子の下端点を満たす。また各nodeはそれをrootとする部分木の最大値を格納する。

# 15 動的計画法 dynamic programming

動的計画法の開発

- 最適解の構造を特徴づける
- 最適解の値を再帰的に定義する
- （多くの場合はボトムアップで）計算する
- 計算結果から1つの最適解を構成する

動的計画法を使うときに注意することは、部分構造最適性 optimal substructure が適用できること。また部分問題重複性 overlapping subproblems を持つこと。可能なら部分問題の総数が入力サイズの多項式であるとよい。

## ロッド切出し問題 rod-cutting problem

長さnの棒がある。これを切り出す。切り出した棒は長さiによって価格piが決まっている。合計金額を最大化したい。

この問題は部分構造最適性がある。

`長さnの最適解 = max(pi + 長さn-iの最適解)`

トップダウンでメモ化もせずに再帰的に解くと計算量が2^nのオーダーになってしまう。解決策を2つ検討する。

- 履歴管理によるトップダウン方式 top-down with memoization
  - トップダウン（nが大きい方からの計算）だが、あるiでの最適解が求まった場合はそれを保存しておく（memoize）。再度同じiの最適解が必要になったら保存した値を利用する。
- ボトムアップ方式 bottom-up method
  - ボトムアップ（nが小さい方からの計算）で進める。こちらも一度求めた最適解をメモに保存しておき、2回目以降はメモの値を利用する。問題の部分構造性質によるが、ボトムアップのほうがオーバーヘッドが小さいことが多い。

問題の構造を理解するのに部分問題グラフを使うと良い。サイズnの最適化問題がサイズmとサイズlに依存するといった依存関係の有向グラフである。ボトムアップ型の動的計画法では、この有向グラフをトポロジカルソートした順に説いていけば良い。

最適値を求めた後に、最適値を出力するための切り出した棒の長さの組み合わせも出力できる。

## 連鎖行列積問題 matrix-chain multiplication problem

行列の列A1, A2, ... Anの行列積を求める。行列積は結合的なので、どのペアから計算をしてもよい。

- e.g. 2つは同じ
  - A1 (A2 A3)
  - (A1 A2) A3

ただし要素（スカラー）同士の乗算の回数は順番によって異なる。どのようなカッコ付をするとスカラー乗算を最小化できるか？というのが連鎖行列積問題。n個の行列の括弧の付け方はΩ(4^n/n^1.5)なので総当たりではできない。

Ai, Ai+1, ..., Ak, ..., Aj という列の行列積の計算を考える。スカラー乗算の最小値を `m[i, j]` とする。Aiは pi-1 x pi 型の行列。

部分構造は次のようになり、部分構造最適性がある。

- 漸化式
  - `m[i, j] = min(m[i, k] + m[k+1, j] + pi-1 * pk * pj)` (i < jのとき)
  - `m[i, j] = 0` (i = jのとき)

最悪実行時間はΩ(n^3)で、メモのためにΘ(n^2)の保存領域が必要。

## 最長共通部分列問題 longest-common-subsequence problem

与えられた2つの列Xと列Yの最長共通部分列LCSを求める問題。共通部分列は順序さえ一致していれば、飛び飛びでよい。

- 次のような列X, Y, Zを考える
  - Xm = [x1, x2, ..., xm]
  - Yn = [y1, y2, ..., yn]
  - Zk = [z1, z2, ..., zk] XとYの任意のLCS
- 部分構造最適性
  - xm = yn なら Zk = Xm-1とYn-1のLCS Zk-1 + 1
  - xm != yn かつ zk != xm なら Zk = Xm-1とYnのLCS
  - xm != yn かつ zk != yn なら Zk = XmとYn-1のLCS
- 漸化式
  - `c[i, j] = 0` (i = 0 or j = 0)
  - `c[i, j] = c[i - 1, j - 1] + 1` (i > 0 and j > 0 and xi = yj)
  - `c[i, j] = max(c[i, j - 1], c[i - 1, j])` (i > 0 and j > 0 and xi != yj)

最悪実行時間はO(n^3)である。

## 最適2分探索木 optimal binary search tree

言語Aから言語Bへの翻訳用の辞書を考える。言語Aで単語はソートされている。2分探索でもよいが、単語の頻度は異なる。頻度の高い単語をrootに近づけることで合計探索回数の期待値を最適化できる。

各ソート済のキーの列 K = [k1, k2, ... kn] から2分探索木を構築する。各キーkiが起こる確率piが与えられている。また `ki < di < ki-1` となるダミーキーの列を考える。これはどのキーにもマッチしない場合のことを想定している。

`探索コストの期待値 = Σ(あるキーの確率 * キーの深さ)`

この探索コストの期待値を最小化する木、最適2分探索木を構築したい。

`w(i, j) = Σt=i~j(キーtの確率) + Σt=i~j(ダミーキーtの確率)` と表すと

- 最適2分探索木の探索コストの期待値 `e[i, j]` の漸化式
  - `e[i, j] = ダミーキーi-1` j = i - 1のとき
  - `e[i, j] = min(e[i, r - 1] + e[r + 1, j] + w(i, j))` j <= iのとき

最悪実行時間はΩ(n^3)となる。

## その他のDP

- バイトニック順回路 bitonic tour
  - 章末問題 15-3
- 編集距離 edit distance
  - 章末問題 15-5
- Viterbi algorighm
  - 章末問題 15-7
- シームカービング
  - 章末問題 15-8
  - 画像を（グニャグニャでもよいが垂直または斜めにつながっている）幅1px分の縦線分だけ画像の横幅を省略する。pixelごとの重要度があり、省略する際は重要度ができるだけ減らないようにしたい。

# 16 貪欲アルゴリズム greedy algorighms

- 貪欲アルゴリズムを利用するときに検討する
  - 部分構造最適性
  - 貪欲な選択によって、ただ1つの部分問題が残る
  - 貪欲な選択が*安全*であることを証明する

## 活動選択問題 activity-selection problem

n個の活動の集合S = {a1, a2, ..., an}があり、各活動aiには開始時刻siと終了時刻fiがある。同時刻にできる活動は1つである。活動数を最大化する組み合わせを求める。集合Sを終了時刻が速い順でソートしておく。

貪欲な戦略では、選択できる活動の集合の中から最も終了時刻が速いものを選択していく。これだけで活動数最大になることは定理16.1で証明される。

## 区間グラフ彩色問題 interval graph coloring problem

問題16.1-4 開始時刻と終了時刻をもった活動の集合がある。同時に利用する最大会議室数を最小化したい。これは活動を頂点、活動時刻が重なる活動同士を辺で結んだグラフで、隣接した頂点が同じ色にならないように彩色する最小の色数をもとめる問題と同じ。

## 0-1ナップサック問題 0-1 knapsack problem

n個の品物があり、各品物iはviの価値があり、wiの重さがある。ナップサックには最大積載量Wがある。どの品物の組み合わせが価値の和を最大化できるか。vi, wi, Wは整数。ある品物iを取る・取らないの0-1なので0-1ナップサック問題と呼ぶ。貪欲アルゴリズムでは最適解にたどり着けないことがある。総当たりの場合O(2^n)。動的計画法を使うとO(n*W)で解ける。

## 有理ナップサック問題 fractional knapsack problem

ナップサック問題で各品物の積載量が連続値になったもの。単位重さ当たりの価値が最も高いものを限界まで積み、残りのスペースに次に単位重さあたりの価値が高いものを...を貪欲に積んでいけば最適化できる。単位重さあたりの価値でソートすれば、O(n*lg(n))で解ける。問題16.2-6によればO(n)時間で解ける。

## ハフマン符号 Huffman code

文字列データの圧縮手法。各文字を出現頻度によって与える表を用いてビット列に変換する。頻度が高い文字は短いビット列にすると効率的。どの符号語も別の符号語の接頭語にならない符号 "接頭語符号" を利用する。2分木で表現できる。貪欲アルゴリズムによって構築できる。図16.5 を読めば実行の流れが見える。

## マトロイド matroid

16.4章参照

## その他貪欲アルゴリズム関連問題

- 釣り銭問題
  - 章末問題16-1
- 最小平均完了時刻スケジューリング
  - 章末問題16-2
- オフラインキャッシュ問題
  - 多数のデータのうち何をキャッシュに載せるか、キャッシュミスを最小化する問題。通常の計算機ではオンラインの問題になるが、オフラインを仮定すると、貪欲法のひとつ、最遠要求優先 furthest-in-future戦略で解ける。

# 17 ならし解析 amortized analysis

ある操作1回のコストではなく、*操作列*の総コストを計算する。操作列の総コストは各操作の最悪時コストの和ではない。計算の仕方が何種類かある。

- 集計法 aggregate method
- 出納法 accounting method
- ポテンシャル法 potential method

この解析を学ぶのはB木やフィボナッチヒープの性能・特徴をより深く理解するためである。

## スタック操作

スタックSを操作する。`push(S, x)`と`pop(S)`はO(1)で実行できるので、長さnの(push or pop)の操作列のコストはΘ(n)で実行できる。

`multipop(S, k)`を考える。スタックSからk個popするが、スタックS内の要素がk個未満のときはすべてpopする。popの回数に比例するので min(S, k) 回の操作が行われる。長さnの(push, pop, or multipop)の操作列のコストを考える。このときスタックの長さの最大値はnなのでmultipopの最悪実行時間はO(n)である。muptipopがn回連続で続くとき、操作列全体の最悪実行時間はO(n^2)である...。この計算量の計算は雑。ならし解析によってO(n)という結果に改良できる。

## 2進カウンタによる係数

0から計数を開始するk bitの2進カウンタを考える。カウンタを1進める increment 操作を考える。n回連続して increment したときビットのフリップ回数の和を求める。1回の increment 操作コストはΘ(k)である。n回の increment ならO(n*k)である...。これも正確にはフリップ回数は2n回以内でありオーダーはO(n)である。

## 動的な表

サイズを予め決めたテーブルにコストO(1)であるinsertとdelete操作を行う。サイズが不足すると新たに大きなサイズのテーブルを確保し、コピーしなければならない。この拡大、もしくは縮小のコストは大きい。拡大・縮小の戦略を間違えると、操作列の総コストはO(n^2)などになってしまう。

テーブルサイズを2^n倍だけ考えることにしよう。飽和したらテーブルサイズを2倍にし、占有率が1/4以下になったらサイズを1/2にする戦略では、n個のinsert, deleteの操作列の総コストはならし解析でO(n)とわかる。

# 18 B木

ディスクアクセス回数を小さくしたいというモチベーションがある。

## B木 B tree

内部node xがn個のキーをもつ場合、n+1個の子nodeを持つ。leaf場合は子を持たない。キーの個数もそのnodeが保持する。

各nodeが持てるキー数に上限と下限を定め、最小次数 minimum dgreeであるtを用いて表す。root以外のnodeは `t - 1` ~ `2 * t - 1` 個のキーを持つことができる。

最も単純なt=2の場合 2-3-4木と呼ぶ。木を低くしたいなら大きなtを利用する。

高さhは `logt((n+1)/2)` 以下になる。

- search
  - ディスクアクセス数 O(logt(n))
  - CPU時間 O(t * logt(n))
- create new B-tree
  - ディスクアクセス数 O(1)
  - CPU時間 O(1)
- splic child
  - 子nodeのキーが飽和した場合は、自身のnodeにキーを追加し、子nodeを2つに分割する
  - ディスクアクセス数 O(1)
  - CPU時間 Θ(t)
- insert
  - ディスクアクセス数 O(logt(n))
  - CPU時間 Θ(t * logt(n))
- delete
  - ディスクアクセス数 O(logt(n))
  - CPU時間 Θ(t * logt(n))

# 19 フィボナッチヒープ

## マージ可能ヒープ

- 以下の5つの操作ができるヒープ
  - make_heap() 空のヒープの作成
  - insert(H, x) xをヒープHに挿入。xのキーはすでに書き込まれている
  - minimum(H) ヒープHに属する最小のキーを持つポインタを返す
  - extract-min(H) ヒープHの最小のキーを抽出し、そのポインタを返す
  - union(H1, H2) 2つのヒープH1, H2を合併し、それを返す。元のヒープは削除される

## フィボナッチヒープ fibonacci heap

マージ可能ヒープのひとつ

- 上記の5つに加え、次の操作も可能
  - descrease_key(H, x, k) ヒープHに属するxのキーをkに下げる
  - delete(H, x) ヒープHからxを削除する

2分ヒープの最悪実行時間と比べて、フィボナッチヒープのならし評価はよい性能を示す。特にunion

- make_heap()
  - 2分ヒープ Θ(1)
  - フィボナッチヒープ Θ(1)
- insert(H, x)
  - 2分ヒープ Θ(lg(n))
  - フィボナッチヒープ Θ(1)
- minimum(H)
  - 2分ヒープ Θ(1)
  - フィボナッチヒープ Θ(1)
- extract-min(H)
  - 2分ヒープ Θ(lg(n))
  - フィボナッチヒープ Θ(lg(n))
- union(H1, H2)
  - 2分ヒープ Θ(n)
  - フィボナッチヒープ Θ(1)
- descrease_key(H, x, k)
  - 2分ヒープ Θ(lg(n))
  - フィボナッチヒープ Θ(1)
- delete(H, x)
  - 2分ヒープ Θ(lg(n))
  - フィボナッチヒープ Θ(lg(n))

グラフ問題のアルゴリズムではdecrease keyをよく用いるのでフィボナッチヒープは良さそうに見えるが、定数部分が大きく、プログラムも複雑なので現実的にはそこまで魅力的ではないらしい。

各nodeは親へのポインタと任意の子へのポインタを持つ。子リストは巡回双方向連結リストで互いに連結している。すべての子のキーは親のキーよりも大きい。またnodeは子の数degreeと、ある接点の子になったあとに子を失ったかを表すmarkを持つ。

nodeの次数の最大値を考える。自明ではないが、19.4の証明によって `D(n)<= logφ(n)` であることがわかる。オーダー的にはO(lg(n))である。

# 20 van Emde Boas木

## van Emde Boas Tree

キーは 0 ~ n-1 の相異なる整数である。各種操作が `O(lg(lg(n)))` で実行できる。
n個の要素を保持する木のroot nodeは、クラスタと呼ばれる√n個の子nodeを持つ。各子nodeは√n個の要素を保持する部分木のrootでもある。
さらに各nodeは最大値、最小値、クラスタのサマリーも持つ。

# 21 互いに素な集合族のためのデータ構造

互いに素な集合の族を管理するデータ構造。各集合の代表元によって集合を識別する。次の操作を持つ。

- make-set(x)
  - xを唯一の要素として持つ集合を生成する。
- union(x, y)
  - xを含む集合とyを含む集合を合併する。
- find-set(x)
  - xを含む集合の代表元へのポインタを返す。

n回のmake-set含み、合計m回のmake-set, union, find-setからなるの操作列を考える。当然m>=n。かつn-1回unionを行うと集合が1つになるのでunionの回数も高々n-1回。

各集合をuni-directional linked-listで表す。linked-listの各要素は集合のメタデータオブジェクトへのポインタを持つ。linked-listの先頭headを代表元とみなす。集合のメタデータはheadとtailのポインタを持つ。

合計m回のmake-set, union, find-setからなるの操作列における1操作あたりのならしコストはΘ(n)である。

unionはメタデータオブジェクトへのポインタの更新が必要。合併するときは短いリストの方を更新したほうがコストが低い。そこで集合のメタデータオブジェクトに集合サイズをもたせる。

これによって合計m回のmake-set, union, find-setからなるの操作列における1操作あたりのならしコストは`Θ(m + n * lg(n))`である。

# 22 基本グラフアルゴリズム

- グラフの表現方法
  - 隣接リスト表現
    - スパースなとき（ `|E| << |V|^2` ）はコンパクトに表現できる。
    - 有効グラフの場合、隣接リストの長さの合計は|E|
    - 無効グラフの場合、隣接リストの長さの合計は2*|E|
  - 隣接行列表現
    - 密なとき（ |E| と |V|^2 が近い ）やある2頂点間に辺が存在するかをすばやく判定するのに有利。
    - 行列サイズは Θ(V^2) となる

## 幅優先探索 breadth-first search

グラフG=(V,E)と始点sが与えられたとき、sから探索可能な頂点を発見かつsからの最小距離を計算し、幅優先木と呼ばれる木を構築する。sからあらゆる頂点への最短路がわかる。

隣接リスト表現を用いた探索アルゴリズムを考える。幅優先探索において頂点はその隣接頂点が探索済みなのかを知るために白、灰、黒のどれかに彩色されている。灰色頂点の集合を管理するためにキューQを利用する。

- 初期化
  - 始点s以外すべての頂点の色colorは白、sからの距離dは∞、親頂点πはNilである。
  - 始点sのcolorは灰、dは0、πはNilである。
  - キューQはsのみ保持している。
- while Qが空ではない
  - u = dequeue(Q)
  - for v of uの隣接頂点:
    - もしvが白なら、v.colorを灰色に、v.dをu.d+1に、v.πをuにし、vをQに挿れる
  - u.colorを黒にする

各頂点はキューに高々1回だけ挿入され、削除される。キュー操作合計でO(V)。隣接リストの長さの和はΘ(V)なのでBFSの総実行時間はO(V+E)である。

## 深さ優先探索 depth-first search

先行部分グラフは深さ優先森（複数の深さ優先木）である。各頂点に2種類のタイムスタンプを押す。そのひとつdはその頂点vを発見して灰に彩色したときであり、もうひとつのfは隣接リストすべてを調べ上げて黒に彩色するとき。|V|*2回分タイムスタンプが押されることになる。

- 初期化
  - すべての頂点の色colorは白、親頂点πはNilである。
  - timeを0にする
- for u of すべての頂点:
  - もしu.colorが白なら dfs-visit(G,u)を実行。u.colorが白以外なら何もしない
- function dfs-visit(G,u):
  - time += 1
  - u.d = time　（タイムスタンプ1つ目：発見時刻）
  - u.color = 灰
  - for v of uの隣接頂点:
    - もしv.colorが白なら v.πをuにして、dfs-visit(G,v)を実行。v.colorが白以外なら何もしない
  - u.color = 黒
  - time += 1
  - u.f = time （タイムスタンプ2つ目：終了時刻）

各頂点は1回ずつしかvisitされないので実行時間はΘ(E)となる。

開始時刻と終了時刻は括弧構造 parenthesis structure となる。

- 辺(u,v)を探索することで初めてvを発見したなら、辺(u,v)は木辺 tree edge である。
- ある頂点uとその祖先vを結ぶ辺(u,v)を後退辺 back dege という。
- ある頂点uとその子孫vを結ぶ辺(u,v)で木辺ではないものを前進辺 forward edge という。
- その他の辺を横断辺 cross edge という。

無向グラフの深さ優先探索森は木辺または後退辺で構成され、前進辺と横断辺は存在しない。

## トポロジカルソート topological sort

依存関係を表すグラフGで、どの順番でやればすべての依存関係を満たした順序に並べられるか。有向非巡回グラフ DAG の深さ優先探索を用いる。

- dfs(G)を行う
  - ある頂点の探索が終わるたびにlinked-listの先頭に挿入する
- できあがったlinked-listはトポロジカルソートされている

## 強連結成分 strongly connected components

有向グラフを強連結成分に分解するのに2回深さ優先探索を行う方法がある。

- dfs(G)を行う
- Gの転置グラフG^Tを計算する
- dfs(G^T)を行うが、終了時刻の降順で探索する
- 深さ優先森の頂点をそれぞれ分離された強連結成分として出力する

# 23 最小全域木

グラフGの全域木 spanning tree （すべての頂点を結ぶ辺の集合）で、重みの和が最小のものを求める。貪欲戦略を用いた2つが紹介されている。

- Kruskalのアルゴリズム
- Primのアルゴリズム

辺を1つずつ辺集合Aに加えていく。Aは常に最小全域木の部分集合である。

無向グラフG=(V,E)のカット(S,V-S)は、Vの分割である。ある辺がSとV-S 2つの集合をまたぐとき、その辺はカット(S,V-S)と交差するという。辺集合Aのどのへんもカットと交差しないとき、そのカットはAを尊重するという。カットと交差する辺の中で最も重みの低い辺を軽い辺 light edge という。

Gの最小全域木の部分集合A、Aを尊重するGのカット(S,V-S)、カット(S,V-S)と交差する軽い辺(u,v)を考える。このとき辺(u,v)はAに対して安全であるという定理23.1を利用する。

## Kruskal's Algorithm

成長させる森に加える安全な辺は、森に属する2つの木C1, C2を連結する辺の中で、重みが最小の辺を用いる。

- 初期化
  - 最小全域木の部分集合A = ∅
  - 互いに素な集合族のためのデータ構造を用意する
    - グラフGの頂点ひとつひとつが1つの集合を形成する
  - G.Eを重み順にソートする
- for 辺(u,v) of G.E（重みの非減少順で）:
  - uとvが異なる集合に属するなら
    - 辺(u,v)をAに加える
    - uの集合とvの集合を合併する
- Aは最小全域木となっている

## Prim's Algorighm

- 初期化
  - すべての頂点のkey = ∞
  - すべての頂点のπ = Nil
  - ある頂点をrと呼ぶ r.key = 0
  - min優先度付きキューQ = G.V
- while Qが空ではない:
  - u = extract-min(Q)
  - for v of uの隣接頂点:
    - もしvがQに含まれていて辺(u,v)の重みがv.keyより小さいなら
      - v.π = u
      - v.key = 辺(u,v)の重み

出来上がった木が最小全域木になっている。

extract-minのコストによるが、、Qが2分ヒープなら全体のコストはO(E * lg(V))

# 24 単一始点最短路問題

重み付き有向グラフG=(V,E)においてuからvへの最短路重みδ(u,v)を求める。パスがなければ∞と定義する。最短路は部分構造最適性を持つので、動的計画法と貪欲アルゴリズムが使えるかもしれない。実際Dijkstraは貪欲アルゴリズム、全頂点間の最短路を求めるFloyd-Warshallは動的計画法である。

負の重みを持つ閉路を含む場合、重み和が無限に小さくなる。

- 緩和 relax
  - 辺(u,v)の緩和はuを経由することでvへの既知の最短路を改善できるかを判定し、改善できるなら更新する。

## Bellman-Ford Algorithm

重みが負である辺の存在を許す単一始点最短路問題を解くアルゴリズム。負の閉路が存在すれば解がないことを報告し、負の閉路がなければ最短路とその重みを返す。グラフとその最短路は三角不等式を満たすとする。

- 初期化
  - すべての頂点の上界dを∞、πをNilにする
  - 開始点s.d = 0
- for |G.V| - 1回 繰り返す:
  - for 辺(u,v) of G.E:
    - relax(u,v,辺(u,v)の重み)
- for 辺(u,v) of G.E:
  - v.d > u.d + 辺(u,v)の重み なら"解無し"
- "解あり"

実行時間はO(VE)である

## 有向非巡回グラフの単一視点最短路

- トポロジカルソートを行う
- ソートされた順に各頂点uに対し、その隣接頂点をすべて緩和する

実行時間Θ(V + E)

## Dijkstra Algorighm

すべての辺の重みが0以上の場合はBellman-Fordよりも高速に解くことができる。

- 初期化
  - すべての頂点の上界dを∞、πをNilにする
  - 開始点s.d = 0
  - 最短経路が決定された頂点の集合S = ∅
  - min優先度付きキューQ = G.V
- while Qが空ではない:
  - u = extract-min(Q)
  - S = S ∪ {u}
  - for v of uの隣接頂点:
    - relax(u,v,辺(u,v)の重み)

実行時間はO(V^2)。ただしグラフが疎 |E| = o(V^2 / lg(V)) ならばmin優先度付きキューQを2分minヒープを用いることで O((V + E) * lg(V)) となる。

## 線形計画問題

差分制約式系Ax<=bは、線形計画法のm x n型行列Aの各行が1と-1を1つずつ含み、それ以外は0。これは制約グラフ constraint graph に対応づけることができる。

- 制約グラフGは重み付き有向グラフで
  - V = {v0, v1, ..., vn}
  - E = {(vi,vj): xj-xi<=bk はある制約} ∪ {(v0,v1), (v0,v2), ..., (v0,vn)}
- x = (δ(v0,v1), δ(v0,v2), ..., δ(v0,vn)) は実行可能解の1つである

# 25 全点対最短路

単一始点の最短路アルゴリズムを頂点数分実行すれば解けるが、もっとうまく解ける。アルゴリズムには隣接行列表現を用いる。
n x n型の重み行列Wを定める。全点対最短路をn x n型行列Dに出力する。

## 動的計画法による解法

高々m本からなる、頂点iからjへの道の中で最小のものをlij(m)とする。lij(m)はlij(m-1)から導くことができる。lij(0)は明らか。lij(m)からなる行列をL(m)と置く。最短路が閉路になることはないのでmは最大でも頂点数|V|=nである。これを利用してボトムアップで全対の最短路を計算できる。ただしL(m-1)からL(m)を導くのにΘ(n^3)の時間がかかるので、全体ではΘ(n^4)のオーダーとなってしまう。

反復2乗法 repeated squaring を用いるとL(1)->L(2)->L(4)->L(8)...と計算を省略できるので、Θ(n^3 * lg(n))のオーダーになる。

## Floyd-Warshall Algorithm

iからjへのパスの中間頂点を考慮した部分構造最適性を利用する。実行時間O(V^3)で解ける。

## Johnson's Algorighm

疎なグラフの場合は上記2手法より漸近的に速い。O(V^2 * lg(V) + V * E)

- すべての重み0以上の場合、各頂点を始点として1回ずつDijkstraを使えば、、すべての頂点間の最短路を計算できる。フィボナッチヒープによるmin優先度付きキューを用いればO(V^2 * lg(V) + V * E)で実行できる。
- 負の重みが存在するときは、1組の非負の辺重みを新しく計算する。更新する際は全対の最短路が変わらないようにする。

# 26 最大フロー

有向グラフGを考える。入口 source と出口 sink があり、辺を通じて通じて何かを流す。この流れる量をフローと呼ぶ。入口と出口以外の各頂点への流入量と出力量が等しいという条件と、各辺のキャパシティを超えない条件のもとで最大フローを探す問題。

逆並列辺が存在する場合は、仮想頂点を追加することで解決できるので、逆並列辺がない場合のみを考える。

複数の入口（出口）をもつ問題も考えられるが、これも仮想の超入口（超出口）を追加し、各入口（出口）に対して無限のキャパシティを持つ辺を追加することで対応可能になる。

## Ford-Fulkerson method

フローネットワークGとフローfが与えられた。このとき、辺(u,v)の容量c(u,v)とフローf(u,v)の差を残余容量 residual capacity cf(u,v)とする。各辺に対し残余容量>0の辺を残余ネットワーク residual network Gfに加える。

- cf(u,v)
  - c(u,v) - f(u,v) ((u,v) ∈ E)
  - f(v,u) ((v,u) ∈ E)
  - 0 (それ以外)

fをGのフロー、f'をGfのフローとする。fのf'による増加f↑f'を次のように定義する

- (f↑f')(u,v)
  - f(u,v) + f'(u,v) - f'(v,u) ((u,v) ∈ E)
  - 0 (それ以外)

増加可能経路pはGf上の始点sから終点tへの単純路である。p上の最小残余容量だけfを増やすことができる。
Ford-Fulkerson methodの概略は以下のようである。

- フローfを0に初期化する
- while 増加可能経路pが残余ネットワークGfに存在
  - fをpに沿って増やす
- return f

この方法でなぜ最大フローが得られるのか？それは最大フロー最小カット定理 定理26.6 に基づいている。

カット(S,T)と交差する純フロー net flow f(S,T) = Σu∈S (Σv∈T (f(u,v))) - Σu∈S (Σv∈T (f(v,u)))
カット(S,T)の容量 c(S,T) = Σu∈S (Σv∈T (c(u,v)))

最小カットはネットワークのすべてのカットの中で最小容量のカット。

|f| = f(S,T) <= c(S,T)

計算量は増加可能経路の探索アルゴリズムによる。

## Edmonds-Karp algorighm

Ford-Fulkerson method増加可能経路を幅優先探索を用いて探索する。O(V*E^2)

## 2部グラフの最大マッチング

無向グラフG=(V,E)について、辺の部分集合Mで、すべての頂点について接続するMの辺が高々1つしかないものをマッチングという。|M|を最大化するマッチングを最大マッチングという。
2部グラフは、頂点集合Vを互いに素な集合L, Rに分割し、辺EがすべてLとRの間に張られているグラフである。
2部グラフの最大マッチング問題は、最大フローネットワーク問題に変換できる。

# 27 マルチスレッドアルゴリズム

- 並列コンピュータのアーキテクチャ
  - 共有記憶 shared memory
  - 分散記憶 distributed memory
- 並行性プラットフォーム
  - 並列計算資源を調整、スケジュール、管理するためのソフトウェア
  - そのうちのひとつが動的マルチスレッド

並行性キーワード concurrency keyword を用いてマルチスレッドアルゴリズムの解析を行う

- マルチスレッド化キーワード
  - spawn 子手続きを生成する
  - sync spawnで生成された子手続きが終了されるのを待つ
- 並列ループキーサード
  - parallel すべてのループが並列実行可能を意味する
  - new parallelの中で共有記憶内で同じデータにアクセスしないように完全に分離する

マルチスレッド実行では命令の集合を計算DAG computation dag というグラフとして考えるとわかりやすい。

## マルチスレッドの理論的な効率

- 仕事量 work
  - 1台のプロセッサで全体の計算を実行するのに必要な総時間
- スパン span
  - 計算DAGの任意のパスに沿って実行するときの時間の最大値。DAGの最長路・クリティカルパスの頂点数に等しい。

p台のプロセッサ上での実行時間をTpと表す

- 仕事量の法則
  - `Tp >= T1 / p`
  - p台のプロセッサを使っても、実行時間は1/p未満にはできない
- スパンの法則
  - `Tp >= T∞`
  - 理想的な環境で、無限台数を使った場合より速くすることはできない

解析に次の指標を定める

- 高速化率 speedup
  - `T1/Tp` で定義する。
  - 仕事量の法則より `T1/Tp <= p`。
  - `T1/Tp = Θ(p)` なら線形高速化といい、`T1/Tp = p`なら完全線形高速化という。
- 余裕度 parallel slackness
  - `(T1/T∞)/p = T1/(p*T∞)` で定義する
  - 計算の並列度がプロセッサ数を超えている程度を表す。
  - T∞ = T1 / 5 かつ p = 3 なら `T1/(p*T∞)` は　5/3
  - T∞ = T1 / 5 かつ p = 5 なら `T1/(p*T∞)` は　1
  - T∞ = T1 / 5 かつ p = 10 なら `T1/(p*T∞)` は　1/2

## スケジューリング

貪欲スケジューラはどの時点でもできるだけ多くのストランドをプロセッサに割り当てる。p個以上のストランドがある時間ステップに実行可能なら、このステップを完全ステップと呼ぶ。それ以外を不完全ステップと呼ぶ。

- 定理27.1
  - p台のプロセッサを持つ理想並列コンピュータ上で貪欲スケジューラは仕事量T1、スパンT∞のマルチスレッド計算を `Tp <= T1/p + T∞` で実行する
- 系27.2
  - 貪欲スケジューラは任意のマルチスレッドけいs名を最悪の場合の2倍以内の実行時間で実行できる。


# 28 行列演算

Ax = b という連立一次方程式を解く

x = A^(-1)b を解けばいいのだが、これは数値的に不安定（計算途中で丸め誤差が増大する）。代わりに *LUP分解法* という方法を使う。これは数値的に安定し、逆行列を使った計算よりも高速。

- *PA = LU* となるn x n行列P, L, Uを求める。
  - L は単位下三角行列（下三角行列で対角成分が全て1）
  - U は上三角行列
  - P は置換行列（各行、各列に1がひとつだけ、それ以外は0となるもの）
- ステップ
  - Ax = b
  - PAx = Pb
  - LUx = Pb
  - Ux = yと置く
  - Ly = Pb
  - これを前進代入法で解く。Θ(n^2)である。
  - Ux = yを後退代入法で解く。Θ(n^2)である。

前進代入法も後退代入法も中学校レベルの計算

# 29 線形計画法

- *標準形*
  - c, b, xはベクトル Aは行列
  - maximize c^T x
    - subject to
      - Ax <= b
      - x >= 0
  - もし等式条件があれば不等式条件に治す
  - ax + bx = cは
    - ax + bx <= c かつ ax + bx >= c と同値

- *スラック形*
  - いくつかの"等式"といくつかの"一変数>=0"の形

単一始点最短路問題や最大フロー問題は線形計画法として定式化できる。線形計画法で解くのが最速ではないが。

## シンプレックス法 simplex algorighm

- 制約を満たす基底解を取る。この時点では基底解は(0, 0, 0...)
- zを大きくするためx1を制約の中で大きくしていく。最もタイトな制約の非基底変数とx1を交換して新しいスラック形をとる（ピボット）。
- つぎにx3を増やすことを考えよう。...

なぜこの方法で停止するのか、最適解が得られるのか、最初の実行可能基底解の見つけ方が書かれている。29.3

# 30 多項式とFFT

*多項式 Polynominal の乗算*

高々n次の多項式A(x)、B(x)の乗算の結果であるC(x)を求める。

係数表現と座標表現という2つの表現方法を使うことで効率的に（Θ(nlogn)で）計算する。
係数表現（Σajxj）でそのまま計算するとΘ(n^2)

# 31 整数論的アルゴリズム

# 32 文字列照合

# 33 計算幾何学

# 34 NP完全性

# 35 近似アルゴリズム
